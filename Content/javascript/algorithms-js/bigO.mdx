---
title: 'Сложность алгоритмов и нотация Big O'
id: 1
category: 'algorithms-js'
next: '/js/algorithms-js/binary-search'
---


<div className = 'mdHead'>

#### Теги

<div className = 'tag_js'>[Что такое (О большое)](#что-такое-о-большое)</div>  <br/>
<div className = 'tag_js'>[O(1) - Константная слжность](#o1---константная-слжность)</div>  <br/>
<div className = 'tag_js'>[O(N) - Линейная сложность](#on---линейная-сложность)</div>  <br/>
<div className = 'tag_js'>[O(n * n) или O(n2) - Экспоненциальная сложность](#on--n-или-on2---экспоненциальная-сложность)</div>  <br/>
<div className = 'tag_js'>[O(log n) - Логарифмическое время](#olog-n---логарифмическое-время)</div>  <br/>
<div className = 'tag_js'>[Это важно](#это-важно)</div>  <br/>
<div className = 'tag_js'>[О(n * log n) - Логарифмически линейная сложность](#оn--log-n---логарифмически-линейная-сложность)</div>  <br/>
<div className = 'tag_js'>[Итог](#итог)</div> 


</div>

<small> Многие из приведенных здесь алгоритмов я разбираю полностью  в отдельных уроках. Здесь мы говорим лишь об их сложности. </small>

## Что такое (О большое)

<b>О большое (Big O)</b> - это специальная нотация используется для описания асимптотической сложности, то есть скорости роста времени выполнения алгоритма с увеличением размера входных данных. Нужно это для того, что бы понимать насколько быстро или медленно работают алгоритмы.
В О большом, нет коэффициентов, минут, секунд и так далее - Об этом будет наглядно показано в примере про логарифмическую сложность O(log n).

## O(1) - Константная сложность

Такая сложность у нас будет если у нас лёгкий алгоритм который никак не взаимодействует с итерируемыми входными данными. Как например такая лёгкая функция:
```javascript
function sum (x,y) {
  return x + y;
}

sum(10,10);
```
Такая сложность означает, что время выполнения не зависит от входных данных. То есть константная, что значит темп роста это постоянная константа.<br/>
Или вот такой пример:
```javascript
let arr = [1,2,3,4,5];

console.log(arr[2]) // 3
```
Мы просто получаем элемент по индексу, если у нас массив будет из 1000 элементов, то скорость получения одного элемента по индексу как то иозменится? Нет, это и есть O(1).

## O(N) - Линейная сложность

Линейная сложность `O(N)`  - это где время выполнения алгоритма пропорционально размеру входных данных. Если есть какая-то последовательность, будь то перебор списка или последовательность циклов то у всего этого будет сложность `О(N)`<br/>
<b> Линейный поиск</b>:

```javascript
const arr = [1,2,3,4,5];

function linearSearch(value, list) {
    let found = false; 
    let position = -1; 
    let index = 0;

    while(!found && index < list.length) {
      if(list[index] == value) {
        found = true;    
        position = index;
      } else {
        index += 1;
      }
    }

    // если тут еще будут какие то не вложенные друг в друга цилкы, то сложность все равно будет O(N)

    return position;
}


console.log(linearSearch(8,arr)); // -1
console.log(linearSearch(3,arr)); // индекс 2
```
То есть например нам нужно найти имя из массива где есть 20 имён и для того, что его найти в худшем случае с подобным поиском нам понадобится 20 операций. Это и есть линейная сложность.
Еще раз подчерку, что если у нас <b> внутри </b> такого поиска будет хоть <b>10 не вложенных циклов</b> сложность все равно будет <b>линейная</b>.

## O(n * n) или O(n2) - Экспоненциальная сложность

O(n<sup>2</sup>) или O(n * n) - это квадратичная сложность, такие алгоритмы имеют в себе два вложенных цикла: Один нужен для того чтобы проходить по всему массиву, а второй, чтобы находить место очередному элементу в уже отсортированной части.<br/>

<b>Сортировка выбором:</b>

```javascript
const arr = [9,2,3,5,9,1,10,58,-10]; 

function selectionSort(arr) {
    for(let i = 0; i < arr.length; i++) { // внешний цикл
        let indexMin = i;
            for(let j = i+1; j < arr.length; j++) { // внутрений цикл, который  каждую итерацию внешнего цикла будет проходить все элементы в массиве
                if(arr[j] < arr[indexMin]) {
                    indexMin = j;
                }
            }

            let tmp = arr[i]; 
            arr[i] = arr[indexMin];
            arr[indexMin] = tmp; 

    }

    return arr;
}
console.log(selectionSort(arr));
```
Увидели такой алгоритм с двумя циклами, значит это О(n<small>2</small>). Но что если будет подобный алгоритм, но внутри будет еще один  вложенный цикл?
```javascript
// просто псевод пример
function sort(arr) {
  for () { // внешний цикл
    for () { // внутрений цикл, 
      if (true) {
        for () {  // еще внутрений цикл, 
          if (true) {
            // и тд
          }
        }
      }
    }

  }

  return arr;
}

```
В таком случае сложность будет как можно было догадаться O(n<sup>3</sup>) и так далее. Если цикл будет <b>не вложенный</b>, то сложность не изменится.
Вложенные циклы могут значительно увеличивать сложность алгоритма, делая его менее эффективным(но не во всех случаях конечно), поэтому нужно учитывать эту собенность и стремиться к минимизации вложенных циклов, если это возможно. Это все называется экспоненциальная сложность потому что общее число операций в результате увеличивается в геометрической прогрессии.

## O(log n) - Логарифмическое время

Логарифмическое время - это сложность, у которой количество операций уменьшается в два раза с каждой итерацией.
Обычно такая сложность в том случае если мы работаем с более сложными структурами данных, например, деревьями, графами и тд..

* Логарифм это обратная операция возведению в степень. Допустим у нас есть `10 * 10 = 100` - это 10<sup> 2 </sup> степени. В свою очередь логарифм будет обратно этому log<sup>10</sup>100 = 2. То есть если в степени мы ищем то сколько будет если 10 перемножить 2 раза, то в логарифме мы ищем сколько раз нужно перемножить 10, что бы получить 100.<br/>

<b>Алгоритм бинарный поиск:</b>

В бинарном поиске когда мы ищем элемент, мы ищем середину и если позиция искомого элемента допустим больше чем все то, что ниже середины, то эту часть мы отбрасываем. Далее повторяем с оставшейся частью пока не найдем искомый элемент.

```javascript
const array = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];

function binarySearch(array, item) {


  let start = 0; 
  let end = array.length;
  let middle; 
  let found = false; 
  let position = -1; 

  while (found === false && start <= end) { 
    middle = Math.floor((start + end) / 2); 

    if (array[middle] === item) { 
      found = true;
      position = middle; 

      return position; 
    }
    
    if (item < array[middle]) {  // если искомый элемент меньше середины
      end = middle - 1;  // оставляем правую часть
    } 
    else {
      start = middle + 1; // иначе оставляем левую часть
    }
  }
  
  return position; 
}

console.log(binarySearch(array, 4)); // 3
```

## Это важно!

<b> Почему логарифм? </b>

* При каждом шаге бинарного поиска или бинарного дерева множество делится на две части, одна из которых выбрасывается, а вторая остается. Это позволяет сокращать количество возможных вариантов в два раза на каждом шаге. Вспоминаем, что логарифм позволяет узнать нам сколько раз мы должны разделить массив на части(кол операций), что бы найти элемент. В случае с массивом  из `10` элементов в худшем случае нам понадобится `4` операции. log<sub>2</sub><sup>10</sup> = 4 - двойка у нас тут будет всегда, это основание дерева, если бы мы работали с тернарным деревом, там была бы тройка. Но! Мы сейчас не работаем с деревом. Просто бинарный поиск и бинарное дерево используют похожий алгоритм для поиска элементов в отсортированном множестве. Так вот в основании у нас 2, массив из 10 элементов. Сколько раз в худшем случае нам нужно поделить массив на основание? `10/2 = 5, 5/2 = 2.5, 2.5/2 = 1.25, 1.25/2 = 0.625` = 4 операции. В последнем случае округляем и получаем 0.

* Так почему же логарифм? Так вот все потому, что данные делятся на мелкие части, которые обрабатываются за одинаковое время. Таким образом, при увеличении размера входных данных вдвое, алгоритм будет выполняться на одну итерацию больше, а не удваивать время выполнения. Представим, что массив у нас теперь из `20` элементов log<sub>2</sub><sup>20 </sup> = 5 У нас массив стал в два раза больше, но кол операция увеличилось всего лишь на одну. Вот это и есть алгоритм с логарифмическим временем, будь то работа с деревом или бинарный поиск по массиву.

* Теперь самое интересное, вы могли заметить, что работали мы сейчас с логарифмом, но не с нотацией O больше. В O большом нет никаких коэффициентов и количества операций или секунд, минут или чего угодно. В O большом для бинарного поиска на массиве из `10` элементов, сложность будет `O(log n)` и для массива из `20` элементов или хоть из `1000` - сложность будет таже самая O(log n). Нам важен темп роста количества операций с увеличением размера входных данных. И сравнивая алгоритм со сложностью `O(log n)` и алгоритм со сложностью `O(n)`, мы будем знать, что первый алгоритм будет намного быстрее второго, а с увеличением входных данных он будет намного намного быстрее. Вот и вся суть.

* Ну и на полседок скажу про такой принцип "разделяй и властвуй" (divide and conquer) - это метод проектирования алгоритмов, который заключается в разбиении задачи на более мелкие подзадачи и решении их независимо друг от друга, а затем объединении полученных результатов в общее решение исходной задачи. Это мы с вами и обсуждали выше.


## О(n * log n) - Логарифмически линейная сложность

О(n * log n) такая сложность будет когда мы работаем например с массивом как в бинарном поиске или другими структурами, все как с O (log n), то есть все тот же принцип "разделяй и властвуй" . Но при этом цикл в котором это все происходит делает какие либо еще операции. В случае с алгоритмом быстрой сортировки, у нас вообще происходит рекурсия.
```javascript
const values = [2, 27, 14, 52, 31, 96, 73, 47, 22, 6];

function QuickSort(List) {

  if (List.length <= 1) {
    return List;
  }

  const pivot = List[List.length - 1];
  const leftList = []; 
  const rightList = []; 

  for (let i = 0; i < List.length - 1; i++) {

    if (List[i] < pivot) {
      leftList.push(List[i]);

    }
    else {
      rightList.push(List[i]);
    }
  }

  return [...QuickSort(leftList), pivot, ...QuickSort(rightList)]; // вот тут мы снова проходимся по каждому подмассиву
}

console.log(QuickSort(values));
```

 Мы так же как и в бинарном поиске разделяем массив на две части, где меньшие элементы попадают в одну часть, а большие в другую. Затем, для каждой такой части это все повторяется. И получается, что у нас тут как бы сложность как в бинарном поиске O(log n), но из за довольно грузоемкого цикла с рекурсией у нас добавляется N операций и получается O(n * log n). Теперь еще разок другими словами: У нас есть внутри рекурсивная операция, которая разделяет массив на меньшие части, и каждая часть сортируется по отдельности. Это ведет к сложности, равной произведению числа элементов в массиве (n) на количество разбиений (log n), что вместе дают нам сложнсоть O(n * log n).

## Итог.

* Получение элемента коллекции это O(1) или простая функция без итерируемых входных данных, это все будет O(1).
* Перебор коллекции это O(n). Даже если у нас будет несколько циклов, сложность будет таже, главное, что бы они были не вложенны друг в друга.
* Вложенные циклы по той же коллекции это O(n2). Если есть три вложенных цикла, будет уже (On3) и так далее.
* Разделяй и властвуй (Divide and Conquer) всегда O(log n). То есть где мы делим некую структуру на мелкие части.
* Итерации которые используют “Разделяй и властвуй” (Divide and Conquer) это O(n * log n). Если мы используем деление на части O(log n) и при этом это все происходит в неких итерациях, то это O(n * log n).

Ну и в конце я скажу, что следует помнить, это все общая оценка и фактическая сложность алгоритма может зависеть от множества факторов, таких как объем данных, способ их обработки, используемые структуры данных и т.д. 
<br/>
Всем спасбио за внимание. Кому всем? ты тут один.